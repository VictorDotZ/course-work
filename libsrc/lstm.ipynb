{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import gc\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# use pytorch_lightning instead lightning.pytorch because optuna use pytorch_lightning\n",
    "# and using lightning.pytorch produce an error due to importing packages\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "# use leave=False by default, TQDM progress bar harder to configure for me\n",
    "from pytorch_lightning.callbacks import RichProgressBar\n",
    "\n",
    "# disable info about hardware\n",
    "pl.utilities.distributed.log.setLevel(logging.WARNING)\n",
    "pl.accelerators.gpu._log.setLevel(logging.WARNING)\n",
    "\n",
    "import optuna\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "\n",
    "from dataset.sequence_to_price import SeqToPriceDataset\n",
    "from dataset.sequence_to_class import SeqToClassDataset\n",
    "\n",
    "\n",
    "from common.log_scaler import LogScaler\n",
    "\n",
    "from lstm.lit_rnn import LitRNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [\n",
    "    \"avg-block-size\",\n",
    "    \"avg-confirmation-time\",\n",
    "    \"blocks-size\",\n",
    "    \"cost-per-transaction\",\n",
    "    \"difficulty\",\n",
    "    \"estimated-transaction-volume-usd\",\n",
    "    \"estimated-transaction-volume\",\n",
    "    \"fees-usd-per-transaction\",\n",
    "    \"hash-rate\",\n",
    "    \"median-confirmation-time\",\n",
    "    \"mempool-count\",\n",
    "    \"mempool-growth\",\n",
    "    \"mempool-size\",\n",
    "    \"n-payments-per-block\",\n",
    "    \"n-payments\",\n",
    "    \"n-transactions-excluding-popular\",\n",
    "    \"n-transactions-per-block\",\n",
    "    \"n-transactions-total\",\n",
    "    \"n-transactions\",\n",
    "    \"n-unique-addresses\",\n",
    "    \"output-volume\",\n",
    "    \"total-bitcoins\",\n",
    "    \"trade-volume\",\n",
    "    \"transaction-fees-usd\",\n",
    "    \"transaction-fees\",\n",
    "    \"utxo-count\",\n",
    "]\n",
    "TARGETS = [\"market-price\"]\n",
    "VAL_START = pd.to_datetime(\"2022-08-01 00:00:00\")\n",
    "TEST_START = pd.to_datetime(\"2022-12-20 00:00:00\")\n",
    "DATA_PATH = \"../data/btc.csv\"\n",
    "INDEX_COL = \"timestamp\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH, index_col=INDEX_COL)\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df = df.iloc[1:-1]\n",
    "df = df.interpolate()\n",
    "\n",
    "scaler = LogScaler(df)\n",
    "df = scaler.fit_transform(df).copy()\n",
    "df = df.dropna()\n",
    "\n",
    "df_train = df.loc[df.index < VAL_START].copy()\n",
    "df_val = df.loc[(VAL_START <= df.index) & (df.index < TEST_START)].copy()\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # clear previous progress bar for does not showing unnecessary stuff\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 2, 8)\n",
    "    max_epoch = trial.suggest_int(\"max_epoch\", 5, 2000)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 16, 128)\n",
    "    d_hid = trial.suggest_int(\"d_hid\", 2, 256)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.2, 0.8)\n",
    "    sequence_length = trial.suggest_int(\"sequence_length\", 5, 96)\n",
    "    forecast_length = 1\n",
    "\n",
    "    num_inputs = len(FEATURES)\n",
    "    num_outputs = 2\n",
    "\n",
    "    seed_everything(101)\n",
    "\n",
    "    train_dataset = SeqToClassDataset(\n",
    "        df_train, FEATURES, TARGETS, sequence_length, forecast_length\n",
    "    )\n",
    "    val_dataset = SeqToClassDataset(\n",
    "        df_val, FEATURES, TARGETS, sequence_length, forecast_length\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size, True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size, False)\n",
    "\n",
    "    model = LitRNN(\n",
    "        num_inputs, d_hid, num_outputs, num_layers, dropout, \"classification\"\n",
    "    )\n",
    "\n",
    "    version = (\n",
    "        \"\"\n",
    "        + f\"epoch={max_epoch}-\"\n",
    "        + f\"batch_size={batch_size}-\"\n",
    "        + f\"sequence_length={sequence_length}-\"\n",
    "        + f\"n_layers={num_layers}-\"\n",
    "        + f\"d_hid={d_hid}-\"\n",
    "        + f\"dropout={dropout:.2f}\"\n",
    "    )\n",
    "\n",
    "    logger = TensorBoardLogger(\n",
    "        \"G:/ML-storage/tb_logs/\", name=\"lstm_classification_final\", version=version\n",
    "    )\n",
    "    trainer = pl.Trainer(\n",
    "        gpus=1,\n",
    "        min_epochs=1,\n",
    "        max_epochs=max_epoch,\n",
    "        log_every_n_steps=len(train_loader),\n",
    "        logger=logger,\n",
    "        callbacks=[\n",
    "            PyTorchLightningPruningCallback(trial, monitor=\"val_acc_epoch\"),\n",
    "            RichProgressBar(),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    del model\n",
    "    del train_loader\n",
    "    del val_loader\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return trainer.callback_metrics[\"val_acc_epoch\"].item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruner = optuna.pruners.MedianPruner(n_startup_trials=1e2, n_warmup_steps=5e4)\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    pruner=pruner,\n",
    "    storage=\"sqlite:///lstm_classification_final_db.sqlite3\",\n",
    "    study_name=\"lstm_classification\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "study.optimize(objective, n_trials=400)\n",
    "\n",
    "print(\"Number of finished trials:\", len(study.trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57fdf6ced3497be6751aff0d610660c5baf34a48c3eaed9bf5963df6523fe9d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
